{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chemist had two chemical flasks labeled 0 and 1 which consist of two\n",
    "different chemicals. He extracted 3 features from these chemicals in order to\n",
    "distinguish between them, you provided the results derived by the chemicals and\n",
    "your task is to create a model that will label chemical 0 or 1 given its three features\n",
    "and built-in docker and use some library to display that in frontend.\n",
    "Note : Use only pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"chemicals\").getOrCreate()\n",
    "filePath = 'indian_liver_patient.csv'\n",
    "df=spark.read.format(\"csv\").option(\"header\",\"true\").load(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+\n",
      "|Age|Gender|Total_Bilirubin|Direct_Bilirubin|Alkaline_Phosphotase|Alamine_Aminotransferase|Aspartate_Aminotransferase|Total_Protiens|Albumin|Albumin_and_Globulin_Ratio|Dataset|\n",
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+\n",
      "| 72|     2|            113|              80|                 263|                     152|                       177|            58|     40|                        69|      2|\n",
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Assuming you have a DataFrame 'df'\n",
    "distinct_counts = df.agg(*(countDistinct(col).alias(col) for col in df.columns))\n",
    "\n",
    "# The 'distinct_counts' DataFrame will contain the number of unique values in each column\n",
    "distinct_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for column 'Age':\n",
      "+---+-----+\n",
      "|Age|count|\n",
      "+---+-----+\n",
      "| 51|   10|\n",
      "|  7|    2|\n",
      "| 54|    8|\n",
      "| 15|    1|\n",
      "| 11|    1|\n",
      "| 29|    7|\n",
      "| 69|    2|\n",
      "| 42|   21|\n",
      "| 73|    2|\n",
      "| 64|    6|\n",
      "| 30|   10|\n",
      "| 34|    8|\n",
      "|  8|    1|\n",
      "| 28|    8|\n",
      "| 22|    9|\n",
      "| 85|    1|\n",
      "| 52|    7|\n",
      "| 35|   12|\n",
      "| 16|    3|\n",
      "| 47|    6|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Value counts for column 'Gender':\n",
      "+------+-----+\n",
      "|Gender|count|\n",
      "+------+-----+\n",
      "|Female|  142|\n",
      "|  Male|  441|\n",
      "+------+-----+\n",
      "\n",
      "Value counts for column 'Total_Bilirubin':\n",
      "+---------------+-----+\n",
      "|Total_Bilirubin|count|\n",
      "+---------------+-----+\n",
      "|            2.6|    5|\n",
      "|            8.2|    1|\n",
      "|            7.3|    3|\n",
      "|            3.1|    2|\n",
      "|           14.2|    1|\n",
      "|           16.6|    1|\n",
      "|             15|    1|\n",
      "|            4.2|    2|\n",
      "|             11|    1|\n",
      "|           15.8|    1|\n",
      "|           22.5|    1|\n",
      "|           16.4|    1|\n",
      "|              3|    2|\n",
      "|           16.7|    1|\n",
      "|           22.8|    1|\n",
      "|              8|    1|\n",
      "|            2.7|    9|\n",
      "|            3.8|    1|\n",
      "|            1.7|   11|\n",
      "|            4.4|    1|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Value counts for column 'Direct_Bilirubin':\n",
      "+----------------+-----+\n",
      "|Direct_Bilirubin|count|\n",
      "+----------------+-----+\n",
      "|             8.5|    2|\n",
      "|             8.2|    2|\n",
      "|             2.6|    1|\n",
      "|               7|    2|\n",
      "|            14.2|    1|\n",
      "|            12.8|    1|\n",
      "|            17.1|    1|\n",
      "|             4.2|    1|\n",
      "|             0.3|   51|\n",
      "|               3|    5|\n",
      "|             6.1|    1|\n",
      "|             2.7|    3|\n",
      "|             1.7|    2|\n",
      "|             2.9|    1|\n",
      "|             0.7|   11|\n",
      "|             4.5|    2|\n",
      "|             6.2|    1|\n",
      "|             0.2|  194|\n",
      "|            10.8|    1|\n",
      "|             2.4|    1|\n",
      "+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Value counts for column 'Alkaline_Phosphotase':\n",
      "+--------------------+-----+\n",
      "|Alkaline_Phosphotase|count|\n",
      "+--------------------+-----+\n",
      "|                 125|    1|\n",
      "|                2110|    1|\n",
      "|                 574|    1|\n",
      "|                 205|    6|\n",
      "|                 169|    1|\n",
      "|                 272|    5|\n",
      "|                 470|    1|\n",
      "|                 462|    1|\n",
      "|                 282|    8|\n",
      "|                 234|    1|\n",
      "|                 232|    1|\n",
      "|                 155|    2|\n",
      "|                 862|    1|\n",
      "|                 154|    2|\n",
      "|                 200|    2|\n",
      "|                 388|    1|\n",
      "|                 415|    1|\n",
      "|                 279|    2|\n",
      "|                1620|    1|\n",
      "|                 138|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Value counts for column 'Alamine_Aminotransferase':\n",
      "+------------------------+-----+\n",
      "|Alamine_Aminotransferase|count|\n",
      "+------------------------+-----+\n",
      "|                      51|    1|\n",
      "|                     205|    1|\n",
      "|                      15|   14|\n",
      "|                     232|    2|\n",
      "|                      54|    3|\n",
      "|                     155|    1|\n",
      "|                     132|    1|\n",
      "|                     154|    1|\n",
      "|                      11|    2|\n",
      "|                      29|   12|\n",
      "|                      69|    3|\n",
      "|                      42|    9|\n",
      "|                     112|    1|\n",
      "|                      64|    4|\n",
      "|                     308|    1|\n",
      "|                      30|   15|\n",
      "|                      34|    3|\n",
      "|                     133|    2|\n",
      "|                     425|    1|\n",
      "|                      59|    3|\n",
      "+------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Value counts for column 'Aspartate_Aminotransferase':\n",
      "+--------------------------+-----+\n",
      "|Aspartate_Aminotransferase|count|\n",
      "+--------------------------+-----+\n",
      "|                       125|    2|\n",
      "|                        51|    4|\n",
      "|                      1500|    1|\n",
      "|                        15|   11|\n",
      "|                        54|    7|\n",
      "|                       232|    1|\n",
      "|                       155|    1|\n",
      "|                       200|    1|\n",
      "|                        11|    2|\n",
      "|                       101|    1|\n",
      "|                       138|    3|\n",
      "|                        29|   11|\n",
      "|                        42|    9|\n",
      "|                        73|    3|\n",
      "|                        87|    4|\n",
      "|                        64|    1|\n",
      "|                       348|    1|\n",
      "|                        30|   14|\n",
      "|                       406|    1|\n",
      "|                       113|    3|\n",
      "+--------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Value counts for column 'Total_Protiens':\n",
      "+--------------+-----+\n",
      "|Total_Protiens|count|\n",
      "+--------------+-----+\n",
      "|           8.5|    5|\n",
      "|           8.2|    8|\n",
      "|             7|   32|\n",
      "|           7.3|   18|\n",
      "|           8.3|    3|\n",
      "|           9.2|    2|\n",
      "|             3|    1|\n",
      "|           6.1|   18|\n",
      "|             8|   20|\n",
      "|           4.4|    4|\n",
      "|           2.7|    1|\n",
      "|           3.8|    2|\n",
      "|           8.1|    6|\n",
      "|           4.5|    4|\n",
      "|           6.2|   24|\n",
      "|           9.6|    1|\n",
      "|           6.5|   15|\n",
      "|           7.5|   15|\n",
      "|           5.4|   13|\n",
      "|           4.9|    6|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Value counts for column 'Albumin':\n",
      "+-------+-----+\n",
      "|Albumin|count|\n",
      "+-------+-----+\n",
      "|    2.6|   21|\n",
      "|    3.1|   28|\n",
      "|    4.2|   12|\n",
      "|      3|   45|\n",
      "|    4.4|    8|\n",
      "|    2.7|   24|\n",
      "|    3.8|   15|\n",
      "|    1.7|    3|\n",
      "|    2.9|   29|\n",
      "|    4.5|    6|\n",
      "|    2.4|   17|\n",
      "|    2.5|   24|\n",
      "|    4.9|    4|\n",
      "|    3.4|   21|\n",
      "|    1.6|    8|\n",
      "|      5|    1|\n",
      "|    3.3|   21|\n",
      "|    1.8|   12|\n",
      "|    3.5|   23|\n",
      "|    4.3|   14|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Value counts for column 'Albumin_and_Globulin_Ratio':\n",
      "+--------------------------+-----+\n",
      "|Albumin_and_Globulin_Ratio|count|\n",
      "+--------------------------+-----+\n",
      "|                      0.55|    1|\n",
      "|                      0.75|    4|\n",
      "|                      1.38|    3|\n",
      "|                      1.85|    2|\n",
      "|                       0.3|    4|\n",
      "|                      0.74|    1|\n",
      "|                      0.78|    1|\n",
      "|                       1.7|    4|\n",
      "|                       0.7|   53|\n",
      "|                      0.68|    1|\n",
      "|                      1.11|    1|\n",
      "|                      0.95|    2|\n",
      "|                      1.02|    1|\n",
      "|                      1.27|    1|\n",
      "|                      null|    4|\n",
      "|                       2.5|    2|\n",
      "|                      0.76|    2|\n",
      "|                      1.66|    1|\n",
      "|                       1.6|    5|\n",
      "|                      0.87|    1|\n",
      "+--------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Value counts for column 'Dataset':\n",
      "+-------+-----+\n",
      "|Dataset|count|\n",
      "+-------+-----+\n",
      "|      1|  416|\n",
      "|      2|  167|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Assuming you have a DataFrame 'df'\n",
    "value_counts = {}\n",
    "\n",
    "# Iterate over the columns\n",
    "for col in df.columns:\n",
    "    # Group by the column and count the occurrences of each unique value\n",
    "    col_value_counts = df.groupBy(col).agg(count('*').alias('count'))\n",
    "    \n",
    "    # Collect the value counts into a dictionary\n",
    "    value_counts[col] = col_value_counts\n",
    "\n",
    "# Print the value counts for each column\n",
    "for col, counts in value_counts.items():\n",
    "    print(f\"Value counts for column '{col}':\")\n",
    "    counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+\n",
      "|Age|Gender|Total_Bilirubin|Direct_Bilirubin|Alkaline_Phosphotase|Alamine_Aminotransferase|Aspartate_Aminotransferase|Total_Protiens|Albumin|Albumin_and_Globulin_Ratio|Dataset|\n",
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+\n",
      "| 65|Female|            0.7|             0.1|                 187|                      16|                        18|           6.8|    3.3|                       0.9|      1|\n",
      "| 62|  Male|           10.9|             5.5|                 699|                      64|                       100|           7.5|    3.2|                      0.74|      1|\n",
      "| 62|  Male|            7.3|             4.1|                 490|                      60|                        68|             7|    3.3|                      0.89|      1|\n",
      "| 58|  Male|              1|             0.4|                 182|                      14|                        20|           6.8|    3.4|                         1|      1|\n",
      "| 72|  Male|            3.9|               2|                 195|                      27|                        59|           7.3|    2.4|                       0.4|      1|\n",
      "| 46|  Male|            1.8|             0.7|                 208|                      19|                        14|           7.6|    4.4|                       1.3|      1|\n",
      "| 26|Female|            0.9|             0.2|                 154|                      16|                        12|             7|    3.5|                         1|      1|\n",
      "| 29|Female|            0.9|             0.3|                 202|                      14|                        11|           6.7|    3.6|                       1.1|      1|\n",
      "| 17|  Male|            0.9|             0.3|                 202|                      22|                        19|           7.4|    4.1|                       1.2|      2|\n",
      "| 55|  Male|            0.7|             0.2|                 290|                      53|                        58|           6.8|    3.4|                         1|      1|\n",
      "| 57|  Male|            0.6|             0.1|                 210|                      51|                        59|           5.9|    2.7|                       0.8|      1|\n",
      "| 72|  Male|            2.7|             1.3|                 260|                      31|                        56|           7.4|      3|                       0.6|      1|\n",
      "| 64|  Male|            0.9|             0.3|                 310|                      61|                        58|             7|    3.4|                       0.9|      2|\n",
      "| 74|Female|            1.1|             0.4|                 214|                      22|                        30|           8.1|    4.1|                         1|      1|\n",
      "| 61|  Male|            0.7|             0.2|                 145|                      53|                        41|           5.8|    2.7|                      0.87|      1|\n",
      "| 25|  Male|            0.6|             0.1|                 183|                      91|                        53|           5.5|    2.3|                       0.7|      2|\n",
      "| 38|  Male|            1.8|             0.8|                 342|                     168|                       441|           7.6|    4.4|                       1.3|      1|\n",
      "| 33|  Male|            1.6|             0.5|                 165|                      15|                        23|           7.3|    3.5|                      0.92|      2|\n",
      "| 40|Female|            0.9|             0.3|                 293|                     232|                       245|           6.8|    3.1|                       0.8|      1|\n",
      "| 40|Female|            0.9|             0.3|                 293|                     232|                       245|           6.8|    3.1|                       0.8|      1|\n",
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Total_Bilirubin: string (nullable = true)\n",
      " |-- Direct_Bilirubin: string (nullable = true)\n",
      " |-- Alkaline_Phosphotase: string (nullable = true)\n",
      " |-- Alamine_Aminotransferase: string (nullable = true)\n",
      " |-- Aspartate_Aminotransferase: string (nullable = true)\n",
      " |-- Total_Protiens: string (nullable = true)\n",
      " |-- Albumin: string (nullable = true)\n",
      " |-- Albumin_and_Globulin_Ratio: string (nullable = true)\n",
      " |-- Dataset: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the Gender categorical feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Total_Bilirubin: double (nullable = true)\n",
      " |-- Direct_Bilirubin: double (nullable = true)\n",
      " |-- Alkaline_Phosphotase: double (nullable = true)\n",
      " |-- Alamine_Aminotransferase: double (nullable = true)\n",
      " |-- Aspartate_Aminotransferase: double (nullable = true)\n",
      " |-- Total_Protiens: double (nullable = true)\n",
      " |-- Albumin: double (nullable = true)\n",
      " |-- Albumin_and_Globulin_Ratio: string (nullable = true)\n",
      " |-- Dataset: string (nullable = true)\n",
      " |-- GenderIndex: double (nullable = false)\n",
      " |-- GenderVec: vector (nullable = true)\n",
      " |-- Index: long (nullable = false)\n",
      "\n",
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+-----------+-------------+-----+\n",
      "|Age|Gender|Total_Bilirubin|Direct_Bilirubin|Alkaline_Phosphotase|Alamine_Aminotransferase|Aspartate_Aminotransferase|Total_Protiens|Albumin|Albumin_and_Globulin_Ratio|Dataset|GenderIndex|    GenderVec|Index|\n",
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+-----------+-------------+-----+\n",
      "| 65|Female|            0.7|             0.1|               187.0|                    16.0|                      18.0|           6.8|    3.3|                       0.9|      1|        1.0|    (1,[],[])|    0|\n",
      "| 62|  Male|           10.9|             5.5|               699.0|                    64.0|                     100.0|           7.5|    3.2|                      0.74|      1|        0.0|(1,[0],[1.0])|    1|\n",
      "| 62|  Male|            7.3|             4.1|               490.0|                    60.0|                      68.0|           7.0|    3.3|                      0.89|      1|        0.0|(1,[0],[1.0])|    2|\n",
      "| 58|  Male|            1.0|             0.4|               182.0|                    14.0|                      20.0|           6.8|    3.4|                         1|      1|        0.0|(1,[0],[1.0])|    3|\n",
      "| 72|  Male|            3.9|             2.0|               195.0|                    27.0|                      59.0|           7.3|    2.4|                       0.4|      1|        0.0|(1,[0],[1.0])|    4|\n",
      "| 46|  Male|            1.8|             0.7|               208.0|                    19.0|                      14.0|           7.6|    4.4|                       1.3|      1|        0.0|(1,[0],[1.0])|    5|\n",
      "| 26|Female|            0.9|             0.2|               154.0|                    16.0|                      12.0|           7.0|    3.5|                         1|      1|        1.0|    (1,[],[])|    6|\n",
      "| 29|Female|            0.9|             0.3|               202.0|                    14.0|                      11.0|           6.7|    3.6|                       1.1|      1|        1.0|    (1,[],[])|    7|\n",
      "| 17|  Male|            0.9|             0.3|               202.0|                    22.0|                      19.0|           7.4|    4.1|                       1.2|      2|        0.0|(1,[0],[1.0])|    8|\n",
      "| 55|  Male|            0.7|             0.2|               290.0|                    53.0|                      58.0|           6.8|    3.4|                         1|      1|        0.0|(1,[0],[1.0])|    9|\n",
      "| 57|  Male|            0.6|             0.1|               210.0|                    51.0|                      59.0|           5.9|    2.7|                       0.8|      1|        0.0|(1,[0],[1.0])|   10|\n",
      "| 72|  Male|            2.7|             1.3|               260.0|                    31.0|                      56.0|           7.4|    3.0|                       0.6|      1|        0.0|(1,[0],[1.0])|   11|\n",
      "| 64|  Male|            0.9|             0.3|               310.0|                    61.0|                      58.0|           7.0|    3.4|                       0.9|      2|        0.0|(1,[0],[1.0])|   12|\n",
      "| 74|Female|            1.1|             0.4|               214.0|                    22.0|                      30.0|           8.1|    4.1|                         1|      1|        1.0|    (1,[],[])|   13|\n",
      "| 61|  Male|            0.7|             0.2|               145.0|                    53.0|                      41.0|           5.8|    2.7|                      0.87|      1|        0.0|(1,[0],[1.0])|   14|\n",
      "| 25|  Male|            0.6|             0.1|               183.0|                    91.0|                      53.0|           5.5|    2.3|                       0.7|      2|        0.0|(1,[0],[1.0])|   15|\n",
      "| 38|  Male|            1.8|             0.8|               342.0|                   168.0|                     441.0|           7.6|    4.4|                       1.3|      1|        0.0|(1,[0],[1.0])|   16|\n",
      "| 33|  Male|            1.6|             0.5|               165.0|                    15.0|                      23.0|           7.3|    3.5|                      0.92|      2|        0.0|(1,[0],[1.0])|   17|\n",
      "| 40|Female|            0.9|             0.3|               293.0|                   232.0|                     245.0|           6.8|    3.1|                       0.8|      1|        1.0|    (1,[],[])|   18|\n",
      "| 40|Female|            0.9|             0.3|               293.0|                   232.0|                     245.0|           6.8|    3.1|                       0.8|      1|        1.0|    (1,[],[])|   19|\n",
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+-----------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "# Assuming you have a DataFrame 'df' with a column named 'Age'\n",
    "\n",
    "# StringIndexer to convert the 'Age' column to numeric indices\n",
    "indexer = StringIndexer(inputCol='Gender', outputCol='GenderIndex')\n",
    "\n",
    "# OneHotEncoder to perform one-hot encoding on the 'AgeIndex' column\n",
    "encoder = OneHotEncoder(inputCols=['GenderIndex'], outputCols=['GenderVec'])\n",
    "\n",
    "# Create a pipeline to execute the StringIndexer and OneHotEncoder in sequence\n",
    "pipeline = Pipeline(stages=[indexer, encoder])\n",
    "\n",
    "# Fit and transform the DataFrame using the pipeline\n",
    "encoded_df = pipeline.fit(df).transform(df)\n",
    "df_with_index = encoded_df.withColumn(\"Index\", monotonically_increasing_id())\n",
    "\n",
    "# Show the encoded DataFrame\n",
    "\n",
    "df_with_index.printSchema()\n",
    "df_with_index.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the float columns represented as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"fields\":[{\"metadata\":{},\"name\":\"Total_Bilirubin\",\"nullable\":true,\"type\":\"float\"},{\"metadata\":{},\"name\":\"Direct_Bilirubin\",\"nullable\":true,\"type\":\"float\"},{\"metadata\":{},\"name\":\"Alkaline_Phosphotase\",\"nullable\":true,\"type\":\"float\"},{\"metadata\":{},\"name\":\"Alamine_Aminotransferase\",\"nullable\":true,\"type\":\"float\"},{\"metadata\":{},\"name\":\"Aspartate_Aminotransferase\",\"nullable\":true,\"type\":\"float\"},{\"metadata\":{},\"name\":\"Total_Protiens\",\"nullable\":true,\"type\":\"float\"},{\"metadata\":{},\"name\":\"Albumin\",\"nullable\":true,\"type\":\"float\"},{\"metadata\":{},\"name\":\"Albumin_and_Globulin_Ratio\",\"nullable\":true,\"type\":\"float\"},{\"metadata\":{},\"name\":\"Dataset\",\"nullable\":true,\"type\":\"float\"},{\"metadata\":{},\"name\":\"Index\",\"nullable\":false,\"type\":\"float\"}],\"type\":\"struct\"}\n",
      "root\n",
      " |-- Total_Bilirubin: float (nullable = true)\n",
      " |-- Direct_Bilirubin: float (nullable = true)\n",
      " |-- Alkaline_Phosphotase: float (nullable = true)\n",
      " |-- Alamine_Aminotransferase: float (nullable = true)\n",
      " |-- Aspartate_Aminotransferase: float (nullable = true)\n",
      " |-- Total_Protiens: float (nullable = true)\n",
      " |-- Albumin: float (nullable = true)\n",
      " |-- Albumin_and_Globulin_Ratio: float (nullable = true)\n",
      " |-- Dataset: float (nullable = true)\n",
      " |-- Index: float (nullable = false)\n",
      "\n",
      "+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+-----+\n",
      "|Total_Bilirubin|Direct_Bilirubin|Alkaline_Phosphotase|Alamine_Aminotransferase|Aspartate_Aminotransferase|Total_Protiens|Albumin|Albumin_and_Globulin_Ratio|Dataset|Index|\n",
      "+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+-----+\n",
      "|            0.7|             0.1|               187.0|                    16.0|                      18.0|           6.8|    3.3|                       0.9|    1.0|  0.0|\n",
      "|           10.9|             5.5|               699.0|                    64.0|                     100.0|           7.5|    3.2|                      0.74|    1.0|  1.0|\n",
      "|            7.3|             4.1|               490.0|                    60.0|                      68.0|           7.0|    3.3|                      0.89|    1.0|  2.0|\n",
      "|            1.0|             0.4|               182.0|                    14.0|                      20.0|           6.8|    3.4|                       1.0|    1.0|  3.0|\n",
      "|            3.9|             2.0|               195.0|                    27.0|                      59.0|           7.3|    2.4|                       0.4|    1.0|  4.0|\n",
      "|            1.8|             0.7|               208.0|                    19.0|                      14.0|           7.6|    4.4|                       1.3|    1.0|  5.0|\n",
      "|            0.9|             0.2|               154.0|                    16.0|                      12.0|           7.0|    3.5|                       1.0|    1.0|  6.0|\n",
      "|            0.9|             0.3|               202.0|                    14.0|                      11.0|           6.7|    3.6|                       1.1|    1.0|  7.0|\n",
      "|            0.9|             0.3|               202.0|                    22.0|                      19.0|           7.4|    4.1|                       1.2|    2.0|  8.0|\n",
      "|            0.7|             0.2|               290.0|                    53.0|                      58.0|           6.8|    3.4|                       1.0|    1.0|  9.0|\n",
      "|            0.6|             0.1|               210.0|                    51.0|                      59.0|           5.9|    2.7|                       0.8|    1.0| 10.0|\n",
      "|            2.7|             1.3|               260.0|                    31.0|                      56.0|           7.4|    3.0|                       0.6|    1.0| 11.0|\n",
      "|            0.9|             0.3|               310.0|                    61.0|                      58.0|           7.0|    3.4|                       0.9|    2.0| 12.0|\n",
      "|            1.1|             0.4|               214.0|                    22.0|                      30.0|           8.1|    4.1|                       1.0|    1.0| 13.0|\n",
      "|            0.7|             0.2|               145.0|                    53.0|                      41.0|           5.8|    2.7|                      0.87|    1.0| 14.0|\n",
      "|            0.6|             0.1|               183.0|                    91.0|                      53.0|           5.5|    2.3|                       0.7|    2.0| 15.0|\n",
      "|            1.8|             0.8|               342.0|                   168.0|                     441.0|           7.6|    4.4|                       1.3|    1.0| 16.0|\n",
      "|            1.6|             0.5|               165.0|                    15.0|                      23.0|           7.3|    3.5|                      0.92|    2.0| 17.0|\n",
      "|            0.9|             0.3|               293.0|                   232.0|                     245.0|           6.8|    3.1|                       0.8|    1.0| 18.0|\n",
      "|            0.9|             0.3|               293.0|                   232.0|                     245.0|           6.8|    3.1|                       0.8|    1.0| 19.0|\n",
      "+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "numeric_columns = df_with_index.select([col(column).cast(\"float\").alias(column) for column in df_with_index.columns[2:] \n",
    "                                    #  if encoded_df.schema[column].dataType == StringType()\n",
    "                                      if column not in [\"GenderIndex\", \"GenderVec\"] \n",
    "                                      ])\n",
    "print(numeric_columns.schema.json())\n",
    "# numeric_columns = df.columns[2:-1]  # Select numeric columns except 'Age', 'Gender', and 'Dataset'\n",
    "# for column in numeric_columns:\n",
    "#     df = df.withColumn(column, df[column].cast(\"double\"))\n",
    "numeric_columns.printSchema()\n",
    "numeric_columns.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the required columns from encoded_df\n",
    "\n",
    "encoded_column = df_with_index.select(col(\"GenderVec\"),col(\"index\"))\n",
    "# Concatenate the numeric_columns and encoded_columns\n",
    "all_columns = numeric_columns .join(encoded_column,on=[\"index\"])\n",
    "all_columns = all_columns.drop(\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "# from xgboost.spark import SparkXGBRegressor\n",
    "inputCols = all_columns.columns\n",
    "assembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "all_columns = assembler.transform(all_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total_Bilirubin',\n",
       " 'Direct_Bilirubin',\n",
       " 'Alkaline_Phosphotase',\n",
       " 'Alamine_Aminotransferase',\n",
       " 'Aspartate_Aminotransferase',\n",
       " 'Total_Protiens',\n",
       " 'Albumin',\n",
       " 'Albumin_and_Globulin_Ratio',\n",
       " 'Dataset',\n",
       " 'GenderVec']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Total_Bilirubin: float, Direct_Bilirubin: float, Alkaline_Phosphotase: float, Alamine_Aminotransferase: float, Aspartate_Aminotransferase: float, Total_Protiens: float, Albumin: float, Albumin_and_Globulin_Ratio: float, Dataset: float, GenderVec: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]\n",
      "Classification Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = all_columns.randomSplit([0.7, 0.3], seed=42)\n",
    "lr = LogisticRegression(labelCol=\"Dataset\", featuresCol=\"features\")\n",
    "model = lr.fit(train_data)\n",
    "y_pred = model.transform(test_data)\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='Dataset', rawPredictionCol='prediction')\n",
    "classification_score = evaluator.evaluate(y_pred)\n",
    "print(\"Classification Score:\", classification_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|       rawPrediction|raw_count|\n",
      "+--------------------+---------+\n",
      "|[-7.1966301932299...|        1|\n",
      "|[-7.2346698557783...|        1|\n",
      "|[-7.1115042709243...|        1|\n",
      "|[-7.1290993200220...|        1|\n",
      "|[-7.2022189799144...|        2|\n",
      "|[-6.2328763421645...|        1|\n",
      "|[-7.1544401363139...|        1|\n",
      "|[-6.9685857828833...|        1|\n",
      "|[-7.1102081351194...|        1|\n",
      "|[-7.2149595027539...|        1|\n",
      "|[-7.1227013555836...|        1|\n",
      "|[-7.1797752125417...|        1|\n",
      "|[-6.8063873783382...|        1|\n",
      "|[-6.3820925068507...|        1|\n",
      "|[-7.1645508771414...|        1|\n",
      "|[-7.1987485235449...|        1|\n",
      "|[-7.1731584920510...|        1|\n",
      "|[-7.0801493082289...|        1|\n",
      "|[-7.1570912716788...|        1|\n",
      "|[-7.1339444817286...|        1|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|count(rawPrediction)|\n",
      "+--------------------+\n",
      "|                 144|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_values = all_columns.select('Dataset').distinct().collect()\n",
    "distinct_values\n",
    "y_pred.groupby(\"rawPrediction\").agg(count('*').alias(\"raw_count\")).show()\n",
    "y_pred.agg(countDistinct(\"rawPrediction\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|Age|Gender|Total_Bilirubin|Direct_Bilirubin|Alkaline_Phosphotase|Alamine_Aminotransferase|Aspartate_Aminotransferase|Total_Protiens|Albumin|Albumin_and_Globulin_Ratio|Dataset|            features|       rawPrediction|         probability|prediction|\n",
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+--------------------+--------------------+--------------------+----------+\n",
      "| 12|  Male|            0.8|             0.2|               302.0|                    47.0|                      67.0|           6.7|    3.5|                       1.1|    2.0|[0.8,0.2,302.0,47...|[-9.8920319843369...|[1.69731648685040...|       1.0|\n",
      "| 13|  Male|            0.6|             0.1|               320.0|                    28.0|                      56.0|           7.2|    3.6|                       1.0|    2.0|[0.6,0.1,320.0,28...|[-10.042377890855...|[1.39448175342930...|       1.0|\n",
      "| 14|  Male|            0.9|             0.3|               310.0|                    21.0|                      16.0|           8.1|    4.2|                       1.0|    2.0|[0.9,0.3,310.0,21...|[-10.574118865339...|[6.45427841999145...|       1.0|\n",
      "| 14|  Male|            1.4|             0.5|               269.0|                    58.0|                      45.0|           6.7|    3.9|                       1.4|    1.0|[1.4,0.5,269.0,58...|[-10.239970612091...|[1.00297946361958...|       1.0|\n",
      "| 16|  Male|            7.7|             4.1|               268.0|                   213.0|                     168.0|           7.1|    4.0|                       1.2|    1.0|[7.7,4.1,268.0,21...|[-9.8768910405623...|[5.59595862040380...|       1.0|\n",
      "| 17|Female|            0.5|             0.1|               206.0|                    28.0|                      21.0|           7.1|    4.5|                       1.7|    2.0|[0.5,0.1,206.0,28...|[-10.835752781008...|[4.35059622976580...|       1.0|\n",
      "| 17|Female|            0.7|             0.2|               145.0|                    18.0|                      36.0|           7.2|    3.9|                      1.18|    2.0|[0.7,0.2,145.0,18...|[-10.403766695388...|[8.33022644178607...|       1.0|\n",
      "| 18|Female|            0.8|             0.2|               199.0|                    34.0|                      31.0|           6.5|    3.5|                      1.16|    2.0|[0.8,0.2,199.0,34...|[-10.021003926951...|[1.46214404165183...|       1.0|\n",
      "| 18|  Male|            0.6|             0.2|               538.0|                    33.0|                      34.0|           7.5|    3.2|                       0.7|    1.0|[0.6,0.2,538.0,33...|[-9.6934654688328...|[2.15205138420432...|       1.0|\n",
      "| 18|  Male|            0.8|             0.2|               228.0|                    55.0|                      54.0|           6.9|    4.0|                       1.3|    1.0|[0.8,0.2,228.0,55...|[-10.272298108488...|[9.96361411221568...|       1.0|\n",
      "| 18|  Male|            0.8|             0.2|               282.0|                    72.0|                     140.0|           5.5|    2.5|                       0.8|    1.0|[0.8,0.2,282.0,72...|[-8.9207054738370...|[6.39046367950325...|       1.0|\n",
      "| 18|  Male|            1.4|             0.6|               215.0|                   440.0|                     850.0|           5.0|    1.9|                       0.6|    1.0|[1.4,0.6,215.0,44...|[-6.4034407129219...|[2.10965648324975...|       1.0|\n",
      "| 18|  Male|            1.8|             0.7|               178.0|                    35.0|                      36.0|           6.8|    3.6|                       1.1|    1.0|[1.8,0.7,178.0,35...|[-10.135880740166...|[1.21639154471547...|       1.0|\n",
      "| 19|Female|            0.7|             0.2|               186.0|                   166.0|                     397.0|           5.5|    3.0|                       1.2|    1.0|[0.7,0.2,186.0,16...|[-8.7173460043593...|[4.75671756753627...|       1.0|\n",
      "| 20|Female|            0.6|             0.2|               202.0|                    12.0|                      13.0|           6.1|    3.0|                       0.9|    2.0|[0.6,0.2,202.0,12...|[-9.6926482242939...|[2.41227706144610...|       1.0|\n",
      "| 20|  Male|            1.1|             0.5|               128.0|                    20.0|                      30.0|           3.9|    1.9|                      0.95|    2.0|[1.1,0.5,128.0,20...|[-8.8212278693685...|[8.47321889469851...|       1.0|\n",
      "| 21|Female|            0.6|             0.1|               186.0|                    25.0|                      22.0|           6.8|    3.4|                       1.0|    1.0|[0.6,0.1,186.0,25...|[-9.9985728864413...|[1.52351839444881...|       1.0|\n",
      "| 21|  Male|            1.0|             0.3|               142.0|                    27.0|                      21.0|           6.4|    3.5|                       1.2|    2.0|[1.0,0.3,142.0,27...|[-10.091001240634...|[1.32609083323803...|       1.0|\n",
      "| 22|Female|            1.1|             0.3|               138.0|                    14.0|                      21.0|           7.0|    3.8|                       1.1|    2.0|[1.1,0.3,138.0,14...|[-10.341216638137...|[9.14975695263264...|       2.0|\n",
      "| 22|Female|            2.2|             1.0|               215.0|                   159.0|                      51.0|           5.5|    2.5|                       0.8|    1.0|[2.2,1.0,215.0,15...|[-8.8594612707660...|[5.83355133651572...|       1.0|\n",
      "+---+------+---------------+----------------+--------------------+------------------------+--------------------------+--------------+-------+--------------------------+-------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 15:39:12.007 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\arunk\\ineuron-assignments\\ASSESSMENT COMPLETION\\Machine_learning_Assessment\\env\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o2408.legacyInferArrayTypeFromFirstElement. Trace:\npy4j.Py4JException: Method legacyInferArrayTypeFromFirstElement([]) does not exist\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\r\n\tat py4j.Gateway.invoke(Gateway.java:274)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m     st\u001b[39m.\u001b[39mwrite(predictions)\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[99], line 63\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m input_data \u001b[39m=\u001b[39m {\n\u001b[0;32m     50\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m\"\u001b[39m: age,\n\u001b[0;32m     51\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mGender\u001b[39m\u001b[39m\"\u001b[39m: gender,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAlbumin_and_Globulin_Ratio\u001b[39m\u001b[39m\"\u001b[39m: albumin_globulin_ratio\n\u001b[0;32m     60\u001b[0m }\n\u001b[0;32m     62\u001b[0m \u001b[39m# Make predictions using the input data\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m predictions \u001b[39m=\u001b[39m make_predictions(input_data)\n\u001b[0;32m     65\u001b[0m \u001b[39m# Display the predictions\u001b[39;00m\n\u001b[0;32m     66\u001b[0m st\u001b[39m.\u001b[39mheader(\u001b[39m\"\u001b[39m\u001b[39mPredictions\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[99], line 20\u001b[0m, in \u001b[0;36mmake_predictions\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_predictions\u001b[39m(data):\n\u001b[0;32m     19\u001b[0m     \u001b[39m# Preprocess the input data\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     preprocessed_data \u001b[39m=\u001b[39m preprocess_input(data)\n\u001b[0;32m     22\u001b[0m     \u001b[39m# Convert the preprocessed data to a DMatrix\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     dmatrix \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mDMatrix(preprocessed_data)\n",
      "Cell \u001b[1;32mIn[99], line 4\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_input\u001b[39m(data):\n\u001b[1;32m----> 4\u001b[0m     data \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mcreateDataFrame(data)\n\u001b[0;32m      5\u001b[0m     encoded_df \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mfit(data)\u001b[39m.\u001b[39mtransform(data)\n\u001b[0;32m      6\u001b[0m     df_with_index \u001b[39m=\u001b[39m encoded_df\u001b[39m.\u001b[39mwithColumn(\u001b[39m\"\u001b[39m\u001b[39mIndex\u001b[39m\u001b[39m\"\u001b[39m, monotonically_increasing_id())\n",
      "File \u001b[1;32mc:\\Users\\arunk\\ineuron-assignments\\ASSESSMENT COMPLETION\\Machine_learning_Assessment\\env\\lib\\site-packages\\pyspark\\sql\\session.py:1276\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1271\u001b[0m \u001b[39mif\u001b[39;00m has_pandas \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data, pd\u001b[39m.\u001b[39mDataFrame):\n\u001b[0;32m   1272\u001b[0m     \u001b[39m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(SparkSession, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mcreateDataFrame(  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[0;32m   1275\u001b[0m     )\n\u001b[1;32m-> 1276\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dataframe(\n\u001b[0;32m   1277\u001b[0m     data, schema, samplingRatio, verifySchema  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1278\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\arunk\\ineuron-assignments\\ASSESSMENT COMPLETION\\Machine_learning_Assessment\\env\\lib\\site-packages\\pyspark\\sql\\session.py:1318\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1316\u001b[0m     rdd, struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_createFromRDD(data\u001b[39m.\u001b[39mmap(prepare), schema, samplingRatio)\n\u001b[0;32m   1317\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1318\u001b[0m     rdd, struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_createFromLocal(\u001b[39mmap\u001b[39;49m(prepare, data), schema)\n\u001b[0;32m   1319\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m jrdd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jvm\u001b[39m.\u001b[39mSerDeUtil\u001b[39m.\u001b[39mtoJavaArray(rdd\u001b[39m.\u001b[39m_to_java_object_rdd())\n",
      "File \u001b[1;32mc:\\Users\\arunk\\ineuron-assignments\\ASSESSMENT COMPLETION\\Machine_learning_Assessment\\env\\lib\\site-packages\\pyspark\\sql\\session.py:962\u001b[0m, in \u001b[0;36mSparkSession._createFromLocal\u001b[1;34m(self, data, schema)\u001b[0m\n\u001b[0;32m    959\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data)\n\u001b[0;32m    961\u001b[0m \u001b[39mif\u001b[39;00m schema \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m--> 962\u001b[0m     struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inferSchemaFromList(data, names\u001b[39m=\u001b[39;49mschema)\n\u001b[0;32m    963\u001b[0m     converter \u001b[39m=\u001b[39m _create_converter(struct)\n\u001b[0;32m    964\u001b[0m     tupled_data: Iterable[Tuple] \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(converter, data)\n",
      "File \u001b[1;32mc:\\Users\\arunk\\ineuron-assignments\\ASSESSMENT COMPLETION\\Machine_learning_Assessment\\env\\lib\\site-packages\\pyspark\\sql\\session.py:834\u001b[0m, in \u001b[0;36mSparkSession._inferSchemaFromList\u001b[1;34m(self, data, names)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcan not infer schema from empty dataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    833\u001b[0m infer_dict_as_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jconf\u001b[39m.\u001b[39minferDictAsStruct()\n\u001b[1;32m--> 834\u001b[0m infer_array_from_first_element \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jconf\u001b[39m.\u001b[39;49mlegacyInferArrayTypeFromFirstElement()\n\u001b[0;32m    835\u001b[0m prefer_timestamp_ntz \u001b[39m=\u001b[39m is_timestamp_ntz_preferred()\n\u001b[0;32m    836\u001b[0m schema \u001b[39m=\u001b[39m reduce(\n\u001b[0;32m    837\u001b[0m     _merge_type,\n\u001b[0;32m    838\u001b[0m     (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    847\u001b[0m     ),\n\u001b[0;32m    848\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\arunk\\ineuron-assignments\\ASSESSMENT COMPLETION\\Machine_learning_Assessment\\env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\arunk\\ineuron-assignments\\ASSESSMENT COMPLETION\\Machine_learning_Assessment\\env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    168\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\arunk\\ineuron-assignments\\ASSESSMENT COMPLETION\\Machine_learning_Assessment\\env\\lib\\site-packages\\py4j\\protocol.py:330\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m             \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m         \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m             \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n\u001b[0;32m    333\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    335\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    336\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name))\n",
      "\u001b[1;31mPy4JError\u001b[0m: An error occurred while calling o2408.legacyInferArrayTypeFromFirstElement. Trace:\npy4j.Py4JException: Method legacyInferArrayTypeFromFirstElement([]) does not exist\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\r\n\tat py4j.Gateway.invoke(Gateway.java:274)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\n\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "# Define a function to preprocess the input data\n",
    "def preprocess_input(data):\n",
    "    data = spark.createDataFrame(data)\n",
    "    encoded_df = pipeline.fit(data).transform(data)\n",
    "    df_with_index = encoded_df.withColumn(\"Index\", monotonically_increasing_id())\n",
    "    numeric_columns = df_with_index.select([col(column).cast(\"float\").alias(column) for column in df_with_index.columns[2:] \n",
    "                                        #  if encoded_df.schema[column].dataType == StringType()\n",
    "                                        if column not in [\"GenderIndex\", \"GenderVec\"] \n",
    "                                        ])\n",
    "    encoded_column = df_with_index.select(col(\"GenderVec\"),col(\"index\"))\n",
    "    # Concatenate the numeric_columns and encoded_columns\n",
    "    all_columns = numeric_columns .join(encoded_column,on=[\"index\"])\n",
    "    all_columns = all_columns.drop(\"index\")\n",
    "\n",
    "    return all_columns\n",
    "\n",
    "def make_predictions(data):\n",
    "    # Preprocess the input data\n",
    "    preprocessed_data = preprocess_input(data)\n",
    "\n",
    "    # Convert the preprocessed data to a DMatrix\n",
    "    dmatrix = model.DMatrix(preprocessed_data)\n",
    "\n",
    "    # Make predictions using the XGBoost model\n",
    "    predictions = model.predict(dmatrix)\n",
    "\n",
    "    return predictions\n",
    "def main():\n",
    "    # Set the app title\n",
    "    st.title(\"Indian Liver Patient\")\n",
    "    st.write(\"Displaying the results of the predictions\")\n",
    "\n",
    "    st.write(f\"classification_score : {classification_score}\")\n",
    "\n",
    "    # Create input fields for the features\n",
    "    age = st.number_input(\"Age\", value=12)\n",
    "    gender = st.selectbox(\"Gender\", [\"Male\", \"Female\"])\n",
    "    total_bilirubin = st.number_input(\"Total Bilirubin\", value=0.8)\n",
    "    direct_bilirubin = st.number_input(\"Direct Bilirubin\", value=0.2)\n",
    "    alkaline_phosphotase = st.number_input(\"Alkaline Phosphotase\", value=302.0)\n",
    "    alamine_aminotransferase = st.number_input(\"Alamine Aminotransferase\", value=47.0)\n",
    "    aspartate_aminotransferase = st.number_input(\"Aspartate Aminotransferase\", value=67.0)\n",
    "    total_protiens = st.number_input(\"Total Protiens\", value=6.7)\n",
    "    albumin = st.number_input(\"Albumin\", value=3.5)\n",
    "    albumin_globulin_ratio = st.number_input(\"Albumin and Globulin Ratio\", value=1.1)\n",
    "\n",
    "    # Create a dictionary with the input data\n",
    "    input_data = {\n",
    "        \"Age\": age,\n",
    "        \"Gender\": gender,\n",
    "        \"Total_Bilirubin\": total_bilirubin,\n",
    "        \"Direct_Bilirubin\": direct_bilirubin,\n",
    "        \"Alkaline_Phosphotase\": alkaline_phosphotase,\n",
    "        \"Alamine_Aminotransferase\": alamine_aminotransferase,\n",
    "        \"Aspartate_Aminotransferase\": aspartate_aminotransferase,\n",
    "        \"Total_Protiens\": total_protiens,\n",
    "        \"Albumin\": albumin,\n",
    "        \"Albumin_and_Globulin_Ratio\": albumin_globulin_ratio\n",
    "    }\n",
    "\n",
    "    # Make predictions using the input data\n",
    "    predictions = make_predictions(input_data)\n",
    "\n",
    "    # Display the predictions\n",
    "    st.header(\"Predictions\")\n",
    "    st.write(predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
